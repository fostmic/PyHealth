{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91abc232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef50c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "from pyhealth.datasets import BaseDataset\n",
    "\n",
    "class SleepQADataset(BaseDataset):\n",
    "    \"\"\"\n",
    "    Output Dataset \n",
    "    \n",
    "\n",
    "    References:\n",
    "        - SleepQA: A Health Coaching Dataset on Sleep for Extractive Question Answering\n",
    "        -- Iva Bojic, Qi Chwen Ong, Megh Thakkar, Esha Kamran, Irving Yu Le Shua, Jaime Rei Ern Pang, Jessica Chen, \n",
    "        -- Vaaruni Nayak, Shafiq Joty, Josip Car Proceedings of the 2nd Machine Learning for Health symposium, \n",
    "        -- PMLR 193:199-217, 2022.\n",
    "        -- https://proceedings.mlr.press/v193/bojic22a.html\n",
    "        -- https://github.com/IvaBojic/SleepQA\n",
    "\n",
    "    Data Fields:\n",
    "        - q_p1  question asked to the LLMs(1,2)\n",
    "        - par_1 - answer paragraph from LLM[1]\n",
    "        - par_2 - answer paragraph from LLM[2]\n",
    "        - answer_1 - short value answer from LLM[1]\n",
    "        - answer_2 - short value answer from LLM[2]\n",
    "        - score_a_1 - annotator 1 score for LLM[1] answer\n",
    "        - score_p_1 - annotator 1 score for LLM[2] answer\n",
    "        - score_a_2 - annotator 2 score for LLM[1] answer\n",
    "        - score_p_2 - annotator 2 score for LLM[2] answer\n",
    "        - score_a_3 - annotator 3 score for LLM[1] answer\n",
    "        - score_p_3 - annotator 3 score for LLM[2] answer\n",
    "        - score_a_4 - annotator 4 score for LLM[1] answer\n",
    "        - score_p_4 - annotator 4 score for LLM[2] answer\n",
    "        - score_a_5 - annotator 5 score for LLM[1] answer\n",
    "        - score_p_5 - annotator 5 score for LLM[2] answer\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        dataset_name: Optional[str] = None,\n",
    "        config_path: Optional[str] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (str): Root directory of the dataset.\n",
    "            dataset_name (str, optional): Name of the dataset. Defaults to None.\n",
    "            config_path (str, optional): Path to the configuration file. Defaults to None.\n",
    "        \"\"\"\n",
    "        super().__init__(root, dataset_name, config_path)\n",
    "        self.dataset_name = \"SleepQA\"\n",
    "        self.config_path = config_path or self.get_config_path()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
